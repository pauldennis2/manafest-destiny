{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24529795",
   "metadata": {},
   "source": [
    "## Mana-fest Destiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba49843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3294db",
   "metadata": {},
   "source": [
    "### Load/Download and Preclean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fdce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading draft data from existing file...\n",
      "Loading Scryfall data from existing file...\n"
     ]
    }
   ],
   "source": [
    "# Set file paths\n",
    "DATA_DIR = \"data/\"\n",
    "DRAFT_CSV = os.path.join(DATA_DIR, \"cleaned_data.csv\")\n",
    "SCRYFALL_CSV = os.path.join(DATA_DIR, \"bloomburrow_cleaned.csv\")\n",
    "\n",
    "# Ensure data directory exists\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "# Function to load draft data (skip download if it exists)\n",
    "def load_draft_data():\n",
    "    if os.path.exists(DRAFT_CSV):\n",
    "        print(\"Loading draft data from existing file...\")\n",
    "        return pd.read_csv(DRAFT_CSV)\n",
    "    else:\n",
    "        print(\"Draft file missing. ERROR. CANNOT PROCEED. SELF DESTRUCT IN 5, 4, 3, 2, 1\")\n",
    "        assert(False)\n",
    "\n",
    "# Function to fetch Scryfall data (skip if already saved)\n",
    "def fetch_scryfall_data():\n",
    "    if os.path.exists(SCRYFALL_CSV):\n",
    "        print(\"Loading Scryfall data from existing file...\")\n",
    "        return pd.read_csv(SCRYFALL_CSV)\n",
    "    else:\n",
    "        print(\"Fetching Scryfall API data...\")\n",
    "        url = \"https://api.scryfall.com/cards/search?q=set:blb\"\n",
    "        response = requests.get(url)\n",
    "        data = response.json()[\"data\"]\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(SCRYFALL_CSV, index=False)\n",
    "        return df\n",
    "\n",
    "# Load datasets with idempotency\n",
    "draft_df = load_draft_data()\n",
    "card_df = fetch_scryfall_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f74d9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89797888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data: 175 rows, 40 columns\n",
      "Cleaned file saved as bloomburrow_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "def clean_card_data(card_df: pd.DataFrame, output_file: str) -> None:\n",
    "    \"\"\"Cleans the card dataset by dropping unnecessary columns and saving the processed version.\"\"\"\n",
    "    core_card_data = [\"name\", \"mana_cost\", \"cmc\", \"type_line\", \"oracle_text\", \"colors\", \"color_identity\", \"keywords\", \"rarity\", \"power\", \"toughness\"]\n",
    "    skeptical_keepers = [\"reprint\"]\n",
    "    external_references = [\"oracle_id\", \"multiverse_ids\", \"mtgo_id\", \"arena_id\", \"tcgplayer_id\", \"cardmarket_id\"]\n",
    "    status_and_printing = [\"foil\", \"nonfoil\", \"promo\", \"reprint\", \"variation\", \"security_stamp\", \"frame\", \"full_art\", \"textless\"]\n",
    "    art_and_flavor = [\"artist\", \"illustration_id\", \"flavor_text\", \"border_color\"]\n",
    "    marketplace_and_pricing = [\"prices\", \"purchase_uris\", \"related_uris\"]\n",
    "    metadata_and_links = [\"set\", \"set_name\", \"set_type\", \"set_uri\", \"set_search_uri\", \"scryfall_set_uri\", \"rulings_uri\", \"prints_search_uri\", \"collector_number\"]\n",
    "\n",
    "    drop_list = external_references + status_and_printing + art_and_flavor + marketplace_and_pricing + metadata_and_links\n",
    "    \n",
    "    card_df.drop(columns=drop_list, inplace=True)\n",
    "    card_df.to_csv(output_file, index=False)\n",
    "    print(f\"Processed data: {card_df.shape[0]} rows, {card_df.shape[1]} columns\")\n",
    "    print(f\"Cleaned file saved as {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "raw_file = \"bloomburrow_raw.csv\"\n",
    "clean_file = \"bloomburrow_cleaned.csv\"\n",
    "\n",
    "clean_card_data(card_df, clean_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8b01d1",
   "metadata": {},
   "source": [
    "### Combine Card/Deck Data, Basic Count Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58362932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['draft_id', 'draft_ti fome', 'game_time', 'build_index', 'match_number',\n",
       "       'game_number', 'rank', 'opp_rank', 'main_colors', 'splash_colors',\n",
       "       ...\n",
       "       'tutored_Ygra, Eater of All', 'deck_Ygra, Eater of All',\n",
       "       'sideboard_Ygra, Eater of All', 'opening_hand_Zoraline, Cosmos Caller',\n",
       "       'drawn_Zoraline, Cosmos Caller', 'tutored_Zoraline, Cosmos Caller',\n",
       "       'deck_Zoraline, Cosmos Caller', 'sideboard_Zoraline, Cosmos Caller',\n",
       "       'user_n_games_bucket', 'user_game_win_rate_bucket'],\n",
       "      dtype='object', length=1398)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draft_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cbd16d6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'wins'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\aaeam\\anaconda3\\envs\\win_c0c1\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'wins'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m     deck_df\u001b[38;5;241m.\u001b[39mto_csv(output_file, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeck DataFrame created: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeck_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdeck_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns (Processed up to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_decks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m decks)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[43mgenerate_deck_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdraft_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcard_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirst_analysis.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m, in \u001b[0;36mgenerate_deck_data\u001b[1;34m(draft_df, card_df, output_file, max_decks)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Get list of card names from relevant columns\u001b[39;00m\n\u001b[0;32m     22\u001b[0m deck_list \u001b[38;5;241m=\u001b[39m [col\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeck_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m deck_columns \u001b[38;5;28;01mif\u001b[39;00m group[col]\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m wins, losses \u001b[38;5;241m=\u001b[39m \u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwins\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum(), group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlosses\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     26\u001b[0m non_land_cards \u001b[38;5;241m=\u001b[39m [card \u001b[38;5;28;01mfor\u001b[39;00m card \u001b[38;5;129;01min\u001b[39;00m deck_list \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLand\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m card_df\u001b[38;5;241m.\u001b[39mloc[card, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype_line\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[0;32m     27\u001b[0m avg_mana_curve \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(card_df\u001b[38;5;241m.\u001b[39mloc[card, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcmc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m card \u001b[38;5;129;01min\u001b[39;00m non_land_cards \u001b[38;5;28;01mif\u001b[39;00m card \u001b[38;5;129;01min\u001b[39;00m card_df\u001b[38;5;241m.\u001b[39mindex) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(non_land_cards) \u001b[38;5;28;01mif\u001b[39;00m non_land_cards \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aaeam\\anaconda3\\envs\\win_c0c1\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\aaeam\\anaconda3\\envs\\win_c0c1\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'wins'"
     ]
    }
   ],
   "source": [
    "# Step 4: Extract Card Types\n",
    "def get_card_types(card_df: pd.DataFrame) -> set:\n",
    "    \"\"\"Finds all distinct card types in the dataset.\"\"\"\n",
    "    return {type_line.split()[0] for type_line in card_df[\"type_line\"]}\n",
    "\n",
    "# Step 5: Compute Deck Data\n",
    "def generate_deck_data(draft_df: pd.DataFrame, card_df: pd.DataFrame, output_file: str, max_decks: int = None) -> None:\n",
    "    \"\"\"Aggregates deck performance data with an optional limit and saves it to a CSV file.\"\"\"\n",
    "    card_types = get_card_types(card_df)\n",
    "    #deck_columns = [\"deck_id\", \"wins\", \"losses\", \"avg_mana_curve\", \"bomb_density\", \"color_identity\"] + [f\"num_{ctype.lower()}\" for ctype in card_types]\n",
    "    \n",
    "    # Draft id from that DF just becomes \"deck_id\" in the final\n",
    "    grouped = draft_df.groupby(\"draft_id\")\n",
    "    deck_columns = [col for col in draft_df.columns if col.startswith(\"deck_\")]\n",
    "    deck_df = pd.DataFrame(columns=deck_columns)\n",
    "\n",
    "    for i, (deck_id, group) in enumerate(grouped):\n",
    "        if max_decks and i >= max_decks:\n",
    "            break  # Stop early if max_decks is reached\n",
    "        \n",
    "        # Get list of card names from relevant columns\n",
    "        deck_list = [col.replace(\"deck_\", \"\") for col in deck_columns if group[col].sum() > 0]\n",
    "\n",
    "        wins, losses = group[\"wins\"].sum(), group[\"losses\"].sum()\n",
    "\n",
    "        non_land_cards = [card for card in deck_list if \"Land\" not in card_df.loc[card, \"type_line\"]]\n",
    "        avg_mana_curve = sum(card_df.loc[card, \"cmc\"] for card in non_land_cards if card in card_df.index) / len(non_land_cards) if non_land_cards else 0\n",
    "        bomb_density = sum(1 for card in deck_list if card_df.loc[card, \"rarity\"] in [\"rare\", \"mythic\"]) / len(deck_list)\n",
    "        color_identity = list(set(color for card in deck_list for color in card_df.loc[card, \"color_identity\"]))\n",
    "        type_counts = {f\"num_{ctype.lower()}\": sum(1 for card in deck_list if ctype in card_df.loc[card, \"type_line\"]) for ctype in card_types}\n",
    "\n",
    "        deck_df.loc[len(deck_df)] = {**{\"deck_id\": deck_id, \"wins\": wins, \"losses\": losses, \"avg_mana_curve\": avg_mana_curve, \"bomb_density\": bomb_density, \"color_identity\": color_identity}, **type_counts}\n",
    "    deck_df.to_csv(output_file, index=False)\n",
    "    print(f\"Deck DataFrame created: {deck_df.shape[0]} rows, {deck_df.shape[1]} columns (Processed up to {max_decks} decks)\")\n",
    "\n",
    "\n",
    "generate_deck_data(draft_df, card_df, \"first_analysis.csv\", 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aec025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to read data from: game_data_public.BLB.PremierDraft.csv\n",
      "\n",
      "Analyzing data for the first draft_id: deaa4cdcd3e84d8e8b5a0ea34a0f9d79\n",
      "\n",
      "--- Draft Performance for deaa4cdcd3e84d8e8b5a0ea34a0f9d79 ---\n",
      "Event record: 6-3\n",
      "Win Rate: 66.67%\n",
      "\n",
      "--- Decklist ---\n",
      "Lands:\n",
      "  9x Forest\n",
      "  8x Swamp\n",
      "Spells:\n",
      "  1x Bakersbane Duo\n",
      "  2x Cache Grab\n",
      "  1x Camellia, the Seedmiser\n",
      "  1x Cindering Cutthroat\n",
      "  1x Daggerfang Duo\n",
      "  1x Downwind Ambusher\n",
      "  1x Druid of the Spade\n",
      "  1x Glidedive Duo\n",
      "  1x Hazardroot Herbalist\n",
      "  1x Hazel's Nocturne\n",
      "  1x Head of the Homestead\n",
      "  1x Longstalk Brawl\n",
      "  1x Overprotect\n",
      "  1x Polliwallop\n",
      "  2x Savor\n",
      "  1x Tangle Tumbler\n",
      "  1x Tender Wildguide\n",
      "  1x Thought-Stalker Warlock\n",
      "  2x Three Tree Rootweaver\n",
      "  1x Ygra, Eater of All\n",
      "\n",
      "--- Raw Decklist (Card: Count) ---\n",
      "{'Bakersbane Duo': 1, 'Cache Grab': 2, 'Camellia, the Seedmiser': 1, 'Cindering Cutthroat': 1, 'Daggerfang Duo': 1, 'Downwind Ambusher': 1, 'Druid of the Spade': 1, 'Forest': 9, 'Glidedive Duo': 1, 'Hazardroot Herbalist': 1, \"Hazel's Nocturne\": 1, 'Head of the Homestead': 1, 'Longstalk Brawl': 1, 'Overprotect': 1, 'Polliwallop': 1, 'Savor': 2, 'Swamp': 8, 'Tangle Tumbler': 1, 'Tender Wildguide': 1, 'Thought-Stalker Warlock': 1, 'Three Tree Rootweaver': 2, 'Ygra, Eater of All': 1}\n"
     ]
    }
   ],
   "source": [
    "def analyze_first_full_draft(file_path=\"game_data_public.BLB.PremierDraft.csv\"):\n",
    "    \"\"\"\n",
    "    Reads game-level data, finds the first complete draft, calculates its win rate,\n",
    "    and displays its decklist.\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Attempting to read data from: {file_path}\")\n",
    "\n",
    "    # Strategy: Read in chunks or a larger initial number of rows\n",
    "    # to ensure we capture at least one full draft, then trim.\n",
    "    # A typical draft is 3-9 games, so 50 rows should be more than enough.\n",
    "    chunk_size = 50\n",
    "    df = pd.read_csv(file_path, nrows=chunk_size)\n",
    "\n",
    "    # Identify the first draft_id\n",
    "    first_draft_id = df['draft_id'].iloc[0]\n",
    "    print(f\"\\nAnalyzing data for the first draft_id: {first_draft_id}\")\n",
    "\n",
    "    # Filter to get all rows belonging to this first draft_id\n",
    "    first_draft_df = df[df['draft_id'] == first_draft_id].copy()\n",
    "\n",
    "    if first_draft_df.empty:\n",
    "        print(f\"Error: Could not find full data for draft_id {first_draft_id} within the first {chunk_size} rows. Try increasing chunk_size.\")\n",
    "        return\n",
    "\n",
    "    # --- Calculate Win Rate ---\n",
    "    # We need to sum the 'won' column for the first_draft_df to get total wins\n",
    "    # and count total games to get total losses\n",
    "    total_wins = first_draft_df['won'].sum()\n",
    "    total_games = len(first_draft_df) # Each row is a game\n",
    "    total_losses = total_games - total_wins\n",
    "\n",
    "    if total_games > 0:\n",
    "        win_rate = (total_wins / total_games) * 100\n",
    "        print(f\"\\n--- Draft Performance for {first_draft_id} ---\")\n",
    "        print(f\"Event record: {total_wins}-{total_losses}\")\n",
    "        print(f\"Win Rate: {win_rate:.2f}%\")\n",
    "    else:\n",
    "        print(f\"\\n--- Draft Performance for {first_draft_id} ---\")\n",
    "        print(\"No games played in this event (total_games = 0).\")\n",
    "\n",
    "    # --- Extract Decklist ---\n",
    "    # Find all columns that start with 'deck_'\n",
    "    deck_card_columns = [col for col in first_draft_df.columns if col.startswith('deck_')]\n",
    "\n",
    "    # Assuming the decklist is constant for all games within the draft,\n",
    "    # we can just take the first row's deck data.\n",
    "    # We want card names where the count is > 0.\n",
    "    deck_composition_row = first_draft_df[deck_card_columns].iloc[0]\n",
    "\n",
    "    # Create a dictionary of card_name: count\n",
    "    decklist_raw = {\n",
    "        col.replace('deck_', ''): int(deck_composition_row[col])\n",
    "        for col in deck_composition_row.index\n",
    "        if deck_composition_row[col] > 0\n",
    "    }\n",
    "\n",
    "    # Format the decklist for display\n",
    "    print(\"\\n--- Decklist ---\")\n",
    "    if not decklist_raw:\n",
    "        print(\"No cards found in the deck (or 'deck_' columns not present/empty).\")\n",
    "    else:\n",
    "        # Separate lands from spells for better readability if possible\n",
    "        # (This would be more robust with the Scryfall data, but we can try a heuristic)\n",
    "        lands = {}\n",
    "        spells = {}\n",
    "\n",
    "        for card_name, count in decklist_raw.items():\n",
    "            # Simple heuristic: if it contains 'Forest', 'Island', etc., or is low cmc\n",
    "            # This is NOT robust and would be better with Scryfall's 'type_line'\n",
    "            if 'Forest' in card_name or 'Island' in card_name or 'Swamp' in card_name or \\\n",
    "               'Mountain' in card_name or 'Plains' in card_name or 'Wastes' in card_name:\n",
    "                lands[card_name] = count\n",
    "            else:\n",
    "                spells[card_name] = count\n",
    "\n",
    "        if lands:\n",
    "            print(\"Lands:\")\n",
    "            for card, count in sorted(lands.items()):\n",
    "                print(f\"  {count}x {card}\")\n",
    "        if spells:\n",
    "            print(\"Spells:\")\n",
    "            for card, count in sorted(spells.items()):\n",
    "                print(f\"  {count}x {card}\")\n",
    "\n",
    "    print(\"\\n--- Raw Decklist (Card: Count) ---\")\n",
    "    print(decklist_raw)\n",
    "\n",
    "\n",
    "# --- Run the analysis ---\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_first_full_draft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc01efed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "draft_df = pd.read_csv(\"cleaned_data.csv\")\n",
    "card_df = pd.read_csv(\"bloomburrow_cleaned.csv\").set_index(\"name\")\n",
    "\n",
    "# Find all distinct card types in Bloomburrow\n",
    "card_types = set()\n",
    "for type_line in card_df[\"type_line\"]:\n",
    "    main_type = type_line.split()[0]  # Take the first word (e.g., \"Creature\", \"Artifact\")\n",
    "    card_types.add(main_type)\n",
    "\n",
    "# Create empty Deck DataFrame with dynamic type columns\n",
    "deck_columns = [\"deck_id\", \"wins\", \"losses\", \"avg_mana_curve\", \"bomb_density\", \"color_identity\"] + [f\"num_{ctype.lower()}\" for ctype in card_types]\n",
    "deck_df = pd.DataFrame(columns=deck_columns)\n",
    "\n",
    "# Aggregate deck data\n",
    "grouped = draft_df.groupby(\"deck_id\")\n",
    "\n",
    "for deck_id, group in grouped:\n",
    "    deck_list = group[\"card_name\"].tolist()\n",
    "\n",
    "    # Compute core metrics\n",
    "    wins = group[\"wins\"].sum()\n",
    "    losses = group[\"losses\"].sum()\n",
    "    \n",
    "    # Filter out lands before calculating mana curve\n",
    "    non_land_cards = [card for card in deck_list if \"Land\" not in card_df.loc[card, \"type_line\"]]\n",
    "    avg_mana_curve = sum(card_df.loc[card, \"cmc\"] for card in non_land_cards if card in card_df.index) / len(non_land_cards) if non_land_cards else 0\n",
    "\n",
    "    bomb_density = sum(1 for card in deck_list if card_df.loc[card, \"rarity\"] in [\"rare\", \"mythic\"]) / len(deck_list)\n",
    "    color_identity = list(set(color for card in deck_list for color in card_df.loc[card, \"color_identity\"]))\n",
    "\n",
    "    # Count card types dynamically\n",
    "    type_counts = {f\"num_{ctype.lower()}\": sum(1 for card in deck_list if ctype in card_df.loc[card, \"type_line\"]) for ctype in card_types}\n",
    "\n",
    "    # Append to deck_df\n",
    "    deck_df.loc[len(deck_df)] = {\n",
    "        **{\"deck_id\": deck_id, \"wins\": wins, \"losses\": losses, \"avg_mana_curve\": avg_mana_curve, \"bomb_density\": bomb_density, \"color_identity\": color_identity},\n",
    "        **type_counts\n",
    "    }\n",
    "\n",
    "# Save the structured deck data\n",
    "deck_df.to_csv(\"deck_analysis.csv\", index=False)\n",
    "\n",
    "print(f\"Deck DataFrame created: {deck_df.shape[0]} rows, {deck_df.shape[1]} columns\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb4a00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e285a1c2",
   "metadata": {},
   "source": [
    "### 5/30 parquet and other work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af68979b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted data/bloomburrow/games.csv to data/bloomburrow/games.parquet.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (assuming it's a CSV)\n",
    "csv_file = \"data/bloomburrow/games.csv\"\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Save as Parquet (PyArrow format)\n",
    "parquet_file = \"data/bloomburrow/games.parquet\"\n",
    "df.to_parquet(parquet_file, engine=\"pyarrow\", compression=\"snappy\")  # Snappy is fast & efficient\n",
    "\n",
    "print(f\"Converted {csv_file} to {parquet_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c340afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>object</th>\n",
       "      <th>id</th>\n",
       "      <th>oracle_id</th>\n",
       "      <th>multiverse_ids</th>\n",
       "      <th>mtgo_id</th>\n",
       "      <th>arena_id</th>\n",
       "      <th>tcgplayer_id</th>\n",
       "      <th>cardmarket_id</th>\n",
       "      <th>name</th>\n",
       "      <th>lang</th>\n",
       "      <th>...</th>\n",
       "      <th>prices</th>\n",
       "      <th>related_uris</th>\n",
       "      <th>purchase_uris</th>\n",
       "      <th>power</th>\n",
       "      <th>toughness</th>\n",
       "      <th>all_parts</th>\n",
       "      <th>security_stamp</th>\n",
       "      <th>promo_types</th>\n",
       "      <th>frame_effects</th>\n",
       "      <th>produced_mana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>card</td>\n",
       "      <td>7dd9946b-515e-4e0d-9da2-711e126e9fa6</td>\n",
       "      <td>7b89b7d2-c724-4d5d-9f0b-7d3302ad1168</td>\n",
       "      <td>[669036]</td>\n",
       "      <td>129489.0</td>\n",
       "      <td>91658.0</td>\n",
       "      <td>559491.0</td>\n",
       "      <td>778435.0</td>\n",
       "      <td>Agate Assault</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>{'usd': '0.03', 'usd_foil': '0.06', 'usd_etche...</td>\n",
       "      <td>{'gatherer': 'https://gatherer.wizards.com/Pag...</td>\n",
       "      <td>{'tcgplayer': 'https://partner.tcgplayer.com/c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>card</td>\n",
       "      <td>39ebb84a-1c52-4b07-9bd0-b360523b3a5b</td>\n",
       "      <td>381a3e8e-71dd-48e4-ab62-53478bde4a14</td>\n",
       "      <td>[668996]</td>\n",
       "      <td>129409.0</td>\n",
       "      <td>91618.0</td>\n",
       "      <td>559647.0</td>\n",
       "      <td>778511.0</td>\n",
       "      <td>Agate-Blade Assassin</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>{'usd': '0.04', 'usd_foil': '0.07', 'usd_etche...</td>\n",
       "      <td>{'gatherer': 'https://gatherer.wizards.com/Pag...</td>\n",
       "      <td>{'tcgplayer': 'https://partner.tcgplayer.com/c...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  object                                    id  \\\n",
       "0   card  7dd9946b-515e-4e0d-9da2-711e126e9fa6   \n",
       "1   card  39ebb84a-1c52-4b07-9bd0-b360523b3a5b   \n",
       "\n",
       "                              oracle_id multiverse_ids   mtgo_id  arena_id  \\\n",
       "0  7b89b7d2-c724-4d5d-9f0b-7d3302ad1168       [669036]  129489.0   91658.0   \n",
       "1  381a3e8e-71dd-48e4-ab62-53478bde4a14       [668996]  129409.0   91618.0   \n",
       "\n",
       "   tcgplayer_id  cardmarket_id                  name lang  ...  \\\n",
       "0      559491.0       778435.0         Agate Assault   en  ...   \n",
       "1      559647.0       778511.0  Agate-Blade Assassin   en  ...   \n",
       "\n",
       "                                              prices  \\\n",
       "0  {'usd': '0.03', 'usd_foil': '0.06', 'usd_etche...   \n",
       "1  {'usd': '0.04', 'usd_foil': '0.07', 'usd_etche...   \n",
       "\n",
       "                                        related_uris  \\\n",
       "0  {'gatherer': 'https://gatherer.wizards.com/Pag...   \n",
       "1  {'gatherer': 'https://gatherer.wizards.com/Pag...   \n",
       "\n",
       "                                       purchase_uris power  toughness  \\\n",
       "0  {'tcgplayer': 'https://partner.tcgplayer.com/c...   NaN        NaN   \n",
       "1  {'tcgplayer': 'https://partner.tcgplayer.com/c...     1          3   \n",
       "\n",
       "  all_parts security_stamp promo_types  frame_effects produced_mana  \n",
       "0       NaN            NaN         NaN            NaN           NaN  \n",
       "1       NaN            NaN         NaN            NaN           NaN  \n",
       "\n",
       "[2 rows x 71 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b9ccea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Parquet file we just created\n",
    "parquet_filestr = \"data/bloomburrow/games.parquet\"\n",
    "# if 'games_df' not in locals() or games_df.empty:\n",
    "#     games_df = pd.read_parquet(parquet_filestr, engine=\"pyarrow\")\n",
    "if \"games_df\" not in globals():\n",
    "    games_df = pd.read_parquet(parquet_filestr, engine=\"pyarrow\")\n",
    "cards_df = pd.read_csv(\"data/bloomburrow/cards.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e552f3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           draft_id\n",
      "0  deaa4cdcd3e84d8e8b5a0ea34a0f9d79\n",
      "1  deaa4cdcd3e84d8e8b5a0ea34a0f9d79\n",
      "2  deaa4cdcd3e84d8e8b5a0ea34a0f9d79\n",
      "3  deaa4cdcd3e84d8e8b5a0ea34a0f9d79\n",
      "4  deaa4cdcd3e84d8e8b5a0ea34a0f9d79\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 931230 entries, 0 to 931229\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   draft_id  931230 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 7.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate columnar efficiency by reading only a specific column\n",
    "\n",
    "parquet_file = \"data/bloomburrow/games.parquet\"\n",
    "df = pd.read_parquet(parquet_file, columns=[\"draft_id\"], engine=\"pyarrow\")\n",
    "\n",
    "# Quick check: Print a few rows\n",
    "print(df.head())\n",
    "\n",
    "# Verify column type and memory usage\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbded7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['object', 'id', 'oracle_id', 'multiverse_ids', 'mtgo_id', 'arena_id',\n",
       "       'tcgplayer_id', 'cardmarket_id', 'name', 'lang', 'released_at', 'uri',\n",
       "       'scryfall_uri', 'layout', 'highres_image', 'image_status', 'image_uris',\n",
       "       'mana_cost', 'cmc', 'type_line', 'oracle_text', 'colors',\n",
       "       'color_identity', 'keywords', 'legalities', 'games', 'reserved',\n",
       "       'game_changer', 'foil', 'nonfoil', 'finishes', 'oversized', 'promo',\n",
       "       'reprint', 'variation', 'set_id', 'set', 'set_name', 'set_type',\n",
       "       'set_uri', 'set_search_uri', 'scryfall_set_uri', 'rulings_uri',\n",
       "       'prints_search_uri', 'collector_number', 'digital', 'rarity',\n",
       "       'flavor_text', 'card_back_id', 'artist', 'artist_ids',\n",
       "       'illustration_id', 'border_color', 'frame', 'full_art', 'textless',\n",
       "       'booster', 'story_spotlight', 'edhrec_rank', 'penny_rank', 'preview',\n",
       "       'prices', 'related_uris', 'purchase_uris', 'power', 'toughness',\n",
       "       'all_parts', 'security_stamp', 'promo_types', 'frame_effects',\n",
       "       'produced_mana'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cards_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3462f29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing data for draft_id: deaa4cdcd3e84d8e8b5a0ea34a0f9d79\n",
      "\n",
      "--- Draft Performance for deaa4cdcd3e84d8e8b5a0ea34a0f9d79 ---\n",
      "Event Record: 6-3\n",
      "Win Rate: 66.67%\n",
      "\n",
      "--- Raw Decklist ---\n",
      "{'Bakersbane Duo': 1, 'Cache Grab': 2, 'Camellia, the Seedmiser': 1, 'Cindering Cutthroat': 1, 'Daggerfang Duo': 1, 'Downwind Ambusher': 1, 'Druid of the Spade': 1, 'Forest': 9, 'Glidedive Duo': 1, 'Hazardroot Herbalist': 1, \"Hazel's Nocturne\": 1, 'Head of the Homestead': 1, 'Longstalk Brawl': 1, 'Overprotect': 1, 'Polliwallop': 1, 'Savor': 2, 'Swamp': 8, 'Tangle Tumbler': 1, 'Tender Wildguide': 1, 'Thought-Stalker Warlock': 1, 'Three Tree Rootweaver': 2, 'Ygra, Eater of All': 1}\n"
     ]
    }
   ],
   "source": [
    "def analyze_first_full_draft(games_df):\n",
    "    \"\"\"\n",
    "    Takes a Pandas DataFrame (`games_df`), finds the first complete draft, \n",
    "    calculates its win rate, and returns the raw decklist.\n",
    "\n",
    "    Returns:\n",
    "        dict: Raw decklist with card names as keys and counts as values.\n",
    "    \"\"\"\n",
    "\n",
    "    if games_df.empty:\n",
    "        print(\"Error: DataFrame is empty. Cannot analyze draft.\")\n",
    "        return {}\n",
    "\n",
    "    # Identify the first draft_id\n",
    "    first_draft_id = games_df[\"draft_id\"].iloc[0]\n",
    "    print(f\"\\nAnalyzing data for draft_id: {first_draft_id}\")\n",
    "\n",
    "    # Filter for all rows belonging to this draft_id\n",
    "    first_draft_df = games_df[games_df[\"draft_id\"] == first_draft_id].copy()\n",
    "\n",
    "    # --- Calculate Win Rate ---\n",
    "    total_wins = first_draft_df[\"won\"].sum()\n",
    "    total_games = len(first_draft_df)\n",
    "    total_losses = total_games - total_wins\n",
    "\n",
    "    win_rate = (total_wins / total_games) * 100 if total_games > 0 else 0.0\n",
    "\n",
    "    print(f\"\\n--- Draft Performance for {first_draft_id} ---\")\n",
    "    print(f\"Event Record: {total_wins}-{total_losses}\")\n",
    "    print(f\"Win Rate: {win_rate:.2f}%\")\n",
    "\n",
    "    # --- Extract Decklist ---\n",
    "    deck_card_columns = [col for col in first_draft_df.columns if col.startswith(\"deck_\")]\n",
    "    deck_composition_row = first_draft_df[deck_card_columns].iloc[0]\n",
    "\n",
    "    # Convert to dictionary format: {card_name: count}\n",
    "    decklist_raw = {\n",
    "        col.replace(\"deck_\", \"\"): int(deck_composition_row[col])\n",
    "        for col in deck_composition_row.index\n",
    "        if deck_composition_row[col] > 0\n",
    "    }\n",
    "\n",
    "    return decklist_raw  # Now returning the decklist for further enrichment\n",
    "\n",
    "decklist_raw = analyze_first_full_draft(games_df)\n",
    "print(\"\\n--- Raw Decklist ---\")\n",
    "print(decklist_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4dbdaa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Enhanced Deck Analysis ---\n",
      "Average Mana Value: 1.68\n",
      "Total Creatures: 14\n",
      "                       name  count  cmc                              type_line\n",
      "0            Bakersbane Duo      1  2.0            Creature — Squirrel Raccoon\n",
      "1                Cache Grab      2  2.0                                Instant\n",
      "2   Camellia, the Seedmiser      1  3.0  Legendary Creature — Squirrel Warlock\n",
      "3       Cindering Cutthroat      1  3.0             Creature — Lizard Assassin\n",
      "4            Daggerfang Duo      1  3.0                Creature — Rat Squirrel\n",
      "5         Downwind Ambusher      1  4.0              Creature — Skunk Assassin\n",
      "6        Druid of the Spade      1  3.0                Creature — Rabbit Druid\n",
      "7                    Forest      9  0.0                    Basic Land — Forest\n",
      "8             Glidedive Duo      1  5.0                  Creature — Bat Lizard\n",
      "9      Hazardroot Herbalist      1  3.0                Creature — Rabbit Druid\n",
      "10         Hazel's Nocturne      1  4.0                                Instant\n",
      "11    Head of the Homestead      1  5.0              Creature — Rabbit Citizen\n",
      "12          Longstalk Brawl      1  1.0                                Sorcery\n",
      "13              Overprotect      1  2.0                                Instant\n",
      "14              Polliwallop      1  4.0                                Instant\n",
      "15                    Savor      2  2.0                                Instant\n",
      "16                    Swamp      8  0.0                     Basic Land — Swamp\n",
      "17           Tangle Tumbler      1  3.0                     Artifact — Vehicle\n",
      "18         Tender Wildguide      1  2.0                Creature — Possum Druid\n",
      "19  Thought-Stalker Warlock      1  3.0              Creature — Lizard Warlock\n",
      "20    Three Tree Rootweaver      2  2.0                  Creature — Mole Druid\n",
      "21       Ygra, Eater of All      1  5.0     Legendary Creature — Elemental Cat\n"
     ]
    }
   ],
   "source": [
    "# Convert decklist dictionary to DataFrame\n",
    "decklist_df = pd.DataFrame(decklist_raw.items(), columns=[\"name\", \"count\"])\n",
    "\n",
    "# Merge with Scryfall card data\n",
    "decklist_enriched = decklist_df.merge(cards_df[[\"name\", \"cmc\", \"type_line\"]], on=\"name\", how=\"left\")\n",
    "\n",
    "# Compute basic deck stats\n",
    "avg_mana_value = (decklist_enriched[\"cmc\"] * decklist_enriched[\"count\"]).sum() / decklist_enriched[\"count\"].sum()\n",
    "num_creatures = decklist_enriched[decklist_enriched[\"type_line\"].str.contains(\"Creature\", na=False)][\"count\"].sum()\n",
    "\n",
    "# Display enriched decklist with stats\n",
    "print(f\"\\n--- Enhanced Deck Analysis ---\")\n",
    "print(f\"Average Mana Value: {avg_mana_value:.2f}\")\n",
    "print(f\"Total Creatures: {num_creatures}\")\n",
    "print(decklist_enriched[[\"name\", \"count\", \"cmc\", \"type_line\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a127030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Scryfall API data...\n"
     ]
    }
   ],
   "source": [
    "SCRYFALL_CSV = \"data/bloomburrow/cards.csv\"\n",
    "import requests\n",
    "import os\n",
    "def fetch_scryfall_data():\n",
    "    if os.path.exists(SCRYFALL_CSV):\n",
    "        print(\"Loading Scryfall data from existing file...\")\n",
    "        return pd.read_csv(SCRYFALL_CSV)\n",
    "    \n",
    "    print(\"Fetching Scryfall API data...\")\n",
    "\n",
    "    url = \"https://api.scryfall.com/cards/search?q=set:blb\"\n",
    "    all_data = []  \n",
    "\n",
    "    while url:\n",
    "        response = requests.get(url)\n",
    "        response_data = response.json()\n",
    "        \n",
    "        all_data.extend(response_data[\"data\"])\n",
    "        \n",
    "        # Check if there are more pages\n",
    "        url = response_data.get(\"next_page\", None)  # Fetch next page if available\n",
    "\n",
    "    # Convert full dataset to DataFrame and save\n",
    "    df = pd.DataFrame(all_data)\n",
    "    df.to_csv(SCRYFALL_CSV, index=False)\n",
    "    \n",
    "    return df\n",
    "\n",
    "cards_df = fetch_scryfall_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "win_c0c1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
